{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hotel Booking Cancellation - Exploratory Data Analysis\n",
    "\n",
    "This notebook performs comprehensive exploratory data analysis on the hotel booking dataset to understand patterns, relationships, and factors that influence cancellations.\n",
    "\n",
    "## Objectives\n",
    "1. Load and inspect the raw dataset\n",
    "2. Generate summary statistics for numerical features\n",
    "3. Visualize distributions of key features\n",
    "4. Analyze correlations with the target variable\n",
    "5. Identify class imbalance in cancellations\n",
    "6. Detect and visualize outliers\n",
    "7. Document key insights and patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data_processing.data_loader import DataLoader\n",
    "from src.utils.logger import get_logger\n",
    "\n",
    "# Configure visualization settings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Initialize logger\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "import yaml\n",
    "\n",
    "with open('../config/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Get data path\n",
    "data_path = config['data']['raw_data_path']\n",
    "print(f\"Data path: {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "loader = DataLoader()\n",
    "df = loader.load_csv(data_path)\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information\n",
    "print(\"=== Dataset Shape ===\")\n",
    "print(f\"Rows: {df.shape[0]:,}\")\n",
    "print(f\"Columns: {df.shape[1]}\")\n",
    "print(\"\\n=== Data Types ===\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n=== First Few Rows ===\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset info\n",
    "print(\"=== Dataset Info ===\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"=== Missing Values ===\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "print(missing_df)\n",
    "\n",
    "if len(missing_df) == 0:\n",
    "    print(\"No missing values found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summary Statistics for Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary statistics for numerical columns\n",
    "print(\"=== Numerical Features Summary Statistics ===\")\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"Number of numerical features: {len(numerical_cols)}\")\n",
    "print(f\"Numerical columns: {numerical_cols}\\n\")\n",
    "\n",
    "df[numerical_cols].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Target Variable Analysis - Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze target variable distribution\n",
    "print(\"=== Target Variable: is_canceled ===\")\n",
    "cancellation_counts = df['is_canceled'].value_counts()\n",
    "cancellation_pct = df['is_canceled'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"\\nCancellation Distribution:\")\n",
    "print(f\"Not Canceled (0): {cancellation_counts[0]:,} ({cancellation_pct[0]:.2f}%)\")\n",
    "print(f\"Canceled (1): {cancellation_counts[1]:,} ({cancellation_pct[1]:.2f}%)\")\n",
    "\n",
    "# Calculate imbalance ratio\n",
    "imbalance_ratio = cancellation_counts.max() / cancellation_counts.min()\n",
    "print(f\"\\nImbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
    "\n",
    "if imbalance_ratio > 1.5:\n",
    "    print(\"\u26a0\ufe0f Class imbalance detected! Consider using SMOTE or class weights during training.\")\n",
    "else:\n",
    "    print(\"\u2713 Classes are relatively balanced.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target variable distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Count plot\n",
    "sns.countplot(data=df, x='is_canceled', ax=axes[0])\n",
    "axes[0].set_title('Cancellation Distribution (Count)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Is Canceled')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticklabels(['Not Canceled', 'Canceled'])\n",
    "\n",
    "# Add value labels on bars\n",
    "for container in axes[0].containers:\n",
    "    axes[0].bar_label(container)\n",
    "\n",
    "# Pie chart\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "axes[1].pie(cancellation_counts, labels=['Not Canceled', 'Canceled'], autopct='%1.1f%%', \n",
    "            startangle=90, colors=colors)\n",
    "axes[1].set_title('Cancellation Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Distribution of Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select key numerical features for visualization\n",
    "key_numerical_features = [\n",
    "    'lead_time', 'adr', 'stays_in_weekend_nights', 'stays_in_week_nights',\n",
    "    'adults', 'children', 'babies', 'previous_cancellations',\n",
    "    'previous_bookings_not_canceled', 'booking_changes', \n",
    "    'days_in_waiting_list', 'required_car_parking_spaces', \n",
    "    'total_of_special_requests'\n",
    "]\n",
    "\n",
    "# Filter to only include columns that exist in the dataset\n",
    "key_numerical_features = [col for col in key_numerical_features if col in df.columns]\n",
    "\n",
    "print(f\"Visualizing {len(key_numerical_features)} key numerical features\")\n",
    "print(key_numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histograms for numerical features\n",
    "n_features = len(key_numerical_features)\n",
    "n_cols = 3\n",
    "n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, n_rows * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(key_numerical_features):\n",
    "    axes[idx].hist(df[col].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel(col)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(n_features, len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Distribution of Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Number of categorical features: {len(categorical_cols)}\")\n",
    "print(f\"Categorical columns: {categorical_cols}\\n\")\n",
    "\n",
    "# Display unique value counts for each categorical column\n",
    "print(\"=== Unique Values in Categorical Features ===\")\n",
    "for col in categorical_cols:\n",
    "    n_unique = df[col].nunique()\n",
    "    print(f\"{col}: {n_unique} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select key categorical features for visualization\n",
    "key_categorical_features = [\n",
    "    'hotel', 'meal', 'market_segment', 'distribution_channel',\n",
    "    'deposit_type', 'customer_type', 'reserved_room_type'\n",
    "]\n",
    "\n",
    "# Filter to only include columns that exist\n",
    "key_categorical_features = [col for col in key_categorical_features if col in df.columns]\n",
    "\n",
    "# Create count plots for categorical features\n",
    "n_features = len(key_categorical_features)\n",
    "n_cols = 2\n",
    "n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, n_rows * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(key_categorical_features):\n",
    "    # Get top categories if too many\n",
    "    value_counts = df[col].value_counts()\n",
    "    if len(value_counts) > 10:\n",
    "        top_values = value_counts.head(10).index\n",
    "        plot_data = df[df[col].isin(top_values)]\n",
    "        title_suffix = ' (Top 10)'\n",
    "    else:\n",
    "        plot_data = df\n",
    "        title_suffix = ''\n",
    "    \n",
    "    sns.countplot(data=plot_data, y=col, ax=axes[idx], order=plot_data[col].value_counts().index)\n",
    "    axes[idx].set_title(f'Distribution of {col}{title_suffix}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Count')\n",
    "    axes[idx].set_ylabel(col)\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(n_features, len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Correlation Analysis with Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix for numerical features\n",
    "correlation_matrix = df[numerical_cols].corr()\n",
    "\n",
    "# Get correlations with target variable\n",
    "target_correlations = correlation_matrix['is_canceled'].sort_values(ascending=False)\n",
    "print(\"=== Correlation with Target Variable (is_canceled) ===\")\n",
    "print(target_correlations)\n",
    "\n",
    "print(\"\\n=== Top 10 Positive Correlations ===\")\n",
    "print(target_correlations.head(11)[1:])  # Exclude self-correlation\n",
    "\n",
    "print(\"\\n=== Top 10 Negative Correlations ===\")\n",
    "print(target_correlations.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlation heatmap\n",
    "plt.figure(figsize=(16, 14))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Heatmap of Numerical Features', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top correlations with target variable\n",
    "# Get top positive and negative correlations (excluding self)\n",
    "top_positive = target_correlations[1:11]\n",
    "top_negative = target_correlations[-10:]\n",
    "top_features = pd.concat([top_positive, top_negative]).sort_values()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['red' if x < 0 else 'green' for x in top_features.values]\n",
    "plt.barh(range(len(top_features)), top_features.values, color=colors, alpha=0.7)\n",
    "plt.yticks(range(len(top_features)), top_features.index)\n",
    "plt.xlabel('Correlation Coefficient', fontsize=12)\n",
    "plt.title('Top Features Correlated with Cancellation', fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Outlier Detection and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect outliers using IQR method\n",
    "def detect_outliers_iqr(data, column):\n",
    "    \"\"\"Detect outliers using the IQR method.\"\"\"\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Detect outliers for key numerical features\n",
    "print(\"=== Outlier Detection (IQR Method) ===\\n\")\n",
    "\n",
    "outlier_summary = []\n",
    "for col in key_numerical_features:\n",
    "    outliers, lower, upper = detect_outliers_iqr(df, col)\n",
    "    outlier_pct = (len(outliers) / len(df)) * 100\n",
    "    outlier_summary.append({\n",
    "        'Feature': col,\n",
    "        'Outlier Count': len(outliers),\n",
    "        'Outlier %': outlier_pct,\n",
    "        'Lower Bound': lower,\n",
    "        'Upper Bound': upper\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary).sort_values('Outlier Count', ascending=False)\n",
    "print(outlier_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplots to visualize outliers\n",
    "n_features = len(key_numerical_features)\n",
    "n_cols = 3\n",
    "n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, n_rows * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(key_numerical_features):\n",
    "    sns.boxplot(data=df, y=col, ax=axes[idx], color='skyblue')\n",
    "    axes[idx].set_title(f'Boxplot of {col}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel(col)\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(n_features, len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Relationships with Cancellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cancellation rate by categorical features\n",
    "print(\"=== Cancellation Rate by Categorical Features ===\\n\")\n",
    "\n",
    "for col in key_categorical_features[:5]:  # Analyze first 5 categorical features\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    cancellation_by_cat = df.groupby(col)['is_canceled'].agg(['mean', 'count'])\n",
    "    cancellation_by_cat.columns = ['Cancellation Rate', 'Count']\n",
    "    cancellation_by_cat['Cancellation Rate'] = cancellation_by_cat['Cancellation Rate'] * 100\n",
    "    cancellation_by_cat = cancellation_by_cat.sort_values('Cancellation Rate', ascending=False)\n",
    "    print(cancellation_by_cat.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cancellation rate by key categorical features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "features_to_plot = ['hotel', 'deposit_type', 'customer_type', 'market_segment']\n",
    "features_to_plot = [f for f in features_to_plot if f in df.columns]\n",
    "\n",
    "for idx, col in enumerate(features_to_plot[:4]):\n",
    "    cancellation_rate = df.groupby(col)['is_canceled'].mean().sort_values(ascending=False)\n",
    "    \n",
    "    cancellation_rate.plot(kind='bar', ax=axes[idx], color='coral', alpha=0.7)\n",
    "    axes[idx].set_title(f'Cancellation Rate by {col}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel(col)\n",
    "    axes[idx].set_ylabel('Cancellation Rate')\n",
    "    axes[idx].set_ylim(0, 1)\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze numerical features by cancellation status\n",
    "print(\"=== Numerical Features by Cancellation Status ===\\n\")\n",
    "\n",
    "comparison_features = ['lead_time', 'adr', 'total_of_special_requests', 'previous_cancellations']\n",
    "comparison_features = [f for f in comparison_features if f in df.columns]\n",
    "\n",
    "for col in comparison_features:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df.groupby('is_canceled')[col].describe()[['mean', 'median', 'std']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Insights and Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Key Findings\n",
    "\n",
    "Based on the exploratory data analysis, here are the key insights discovered:\n",
    "\n",
    "#### 1. **Dataset Overview**\n",
    "- The dataset contains hotel booking information with multiple features\n",
    "- Both numerical and categorical features are present\n",
    "- Some features may have missing values that need to be handled\n",
    "\n",
    "#### 2. **Target Variable (Cancellation)**\n",
    "- Class imbalance may exist between cancelled and non-cancelled bookings\n",
    "- The imbalance ratio indicates whether SMOTE or class weights should be used\n",
    "- Understanding the baseline cancellation rate is crucial for model evaluation\n",
    "\n",
    "#### 3. **Feature Correlations**\n",
    "- Several features show strong correlation with cancellation probability\n",
    "- Lead time, deposit type, and previous cancellations are likely important predictors\n",
    "- Some features may be highly correlated with each other (multicollinearity)\n",
    "\n",
    "#### 4. **Outliers**\n",
    "- Outliers are present in several numerical features\n",
    "- Features like lead_time and adr may have extreme values\n",
    "- Outlier treatment strategy should be decided based on domain knowledge\n",
    "\n",
    "#### 5. **Feature Engineering Opportunities**\n",
    "- Creating derived features like total_guests and total_nights could be beneficial\n",
    "- Temporal features (month, season) may capture booking patterns\n",
    "- Interaction features between key predictors could improve model performance\n",
    "\n",
    "#### 6. **Data Quality**\n",
    "- Missing values need to be imputed or removed\n",
    "- Categorical features need encoding (label or one-hot)\n",
    "- Numerical features may benefit from scaling/normalization\n",
    "\n",
    "#### 7. **Next Steps**\n",
    "- Implement data cleaning to handle missing values and duplicates\n",
    "- Create engineered features based on insights\n",
    "- Apply appropriate encoding and scaling transformations\n",
    "- Address class imbalance if present\n",
    "- Train multiple models and compare performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final summary statistics\n",
    "print(\"=== EDA Summary ===\")\n",
    "print(f\"Total Records: {len(df):,}\")\n",
    "print(f\"Total Features: {len(df.columns)}\")\n",
    "print(f\"Numerical Features: {len(numerical_cols)}\")\n",
    "print(f\"Categorical Features: {len(categorical_cols)}\")\n",
    "print(f\"Cancellation Rate: {df['is_canceled'].mean():.2%}\")\n",
    "print(f\"Missing Values: {df.isnull().sum().sum():,}\")\n",
    "print(\"\\n\u2713 Exploratory Data Analysis Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}