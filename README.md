# Hotel Cancellation Optimizer

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-FF4B4B.svg)](https://streamlit.io)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3+-F7931E.svg)](https://scikit-learn.org/)

Un systÃ¨me de Machine Learning pour prÃ©dire les annulations de rÃ©servations d'hÃ´tel et optimiser la gestion du surbooking.

> ğŸ¯ **Objectif** : Aider les hÃ´teliers Ã  maximiser l'occupation des chambres en prÃ©disant les annulations avec 91% de prÃ©cision

## ğŸš€ DÃ©marrage rapide

**Pour les utilisateurs pressÃ©s :**

```bash
# 1. Installer les dÃ©pendances
pip install -r requirements.txt

# 2. TÃ©lÃ©charger le dataset et le placer dans data/raw/

# 3. EntraÃ®ner le modÃ¨le
python run_pipeline.py

# 4. Lancer l'application web
streamlit run app/streamlit_app.py
```

Rendez-vous sur `http://localhost:8501` et commencez Ã  prÃ©dire ! ğŸ‰

---

## ğŸ“‹ Vue d'ensemble

Ce projet dÃ©veloppe un systÃ¨me ML end-to-end qui analyse les donnÃ©es historiques de rÃ©servations pour estimer la probabilitÃ© qu'une rÃ©servation soit annulÃ©e. Le systÃ¨me aide les hÃ´teliers Ã  maximiser l'occupation des chambres tout en minimisant les risques financiers.

### FonctionnalitÃ©s principales

- ğŸ” **Analyse exploratoire des donnÃ©es** : Visualisations et statistiques dÃ©taillÃ©es
- ğŸ§¹ **Pipeline de prÃ©traitement** : Nettoyage, transformation et engineering de features
- ğŸ¤– **EntraÃ®nement multi-modÃ¨les** : Logistic Regression, Random Forest, XGBoost
- ğŸ“Š **Ã‰valuation complÃ¨te** : MÃ©triques de performance et comparaison de modÃ¨les
- ğŸ¯ **Service de prÃ©diction** : API pour prÃ©dictions en temps rÃ©el
- ğŸŒ **Interface web** : Application Streamlit interactive
- âš™ï¸ **Optimisation d'hyperparamÃ¨tres** : Tuning automatique pour maximiser les performances

## ğŸ—ï¸ Architecture

```
hotel-cancellation-optimizer/
â”‚
â”œâ”€â”€ data/                   # DonnÃ©es brutes et traitÃ©es
â”œâ”€â”€ notebooks/              # Jupyter notebooks pour l'analyse
â”œâ”€â”€ src/                    # Code source du projet
â”‚   â”œâ”€â”€ data_processing/    # Chargement et prÃ©traitement
â”‚   â”œâ”€â”€ eda/                # Analyse exploratoire
â”‚   â”œâ”€â”€ modeling/           # EntraÃ®nement et optimisation
â”‚   â”œâ”€â”€ evaluation/         # Ã‰valuation des modÃ¨les
â”‚   â”œâ”€â”€ prediction/         # Service de prÃ©diction
â”‚   â””â”€â”€ utils/              # Utilitaires
â”œâ”€â”€ app/                    # Application web Streamlit
â”œâ”€â”€ models/                 # ModÃ¨les entraÃ®nÃ©s sauvegardÃ©s
â”œâ”€â”€ tests/                  # Tests unitaires et d'intÃ©gration
â”œâ”€â”€ config/                 # Fichiers de configuration
â”œâ”€â”€ logs/                   # Logs d'application
â””â”€â”€ reports/                # Rapports et visualisations

```

## ğŸš€ Installation

### PrÃ©requis

- Python 3.8 ou supÃ©rieur
- pip (gestionnaire de paquets Python)
- 8GB RAM minimum recommandÃ©
- 2GB d'espace disque libre

### Ã‰tapes d'installation

1. **Cloner le repository**
```bash
git clone <repository-url>
cd hotel-cancellation-optimizer
```

2. **CrÃ©er un environnement virtuel**
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

3. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

4. **TÃ©lÃ©charger et prÃ©parer le dataset**

   **Option 1 : TÃ©lÃ©chargement depuis Kaggle**
   - CrÃ©er un compte sur [Kaggle](https://www.kaggle.com/) (gratuit)
   - TÃ©lÃ©charger le dataset "Hotel Booking Demand" : [lien direct](https://www.kaggle.com/datasets/jessemostipak/hotel-booking-demand)
   - Extraire le fichier `hotel_bookings.csv`
   - Placer le fichier dans le dossier `data/raw/`

   **Option 2 : Utilisation de l'API Kaggle**
   ```bash
   # Installer l'API Kaggle
   pip install kaggle
   
   # Configurer les credentials (voir documentation Kaggle)
   # TÃ©lÃ©charger le dataset
   kaggle datasets download -d jessemostipak/hotel-booking-demand
   
   # Extraire et dÃ©placer
   unzip hotel-booking-demand.zip
   mv hotel_bookings.csv data/raw/
   ```

   **VÃ©rification du dataset :**
   ```bash
   # VÃ©rifier que le fichier existe
   ls data/raw/hotel_bookings.csv
   
   # VÃ©rifier la taille (devrait Ãªtre ~20MB)
   # Windows PowerShell
   (Get-Item data/raw/hotel_bookings.csv).length/1MB
   ```

   **CaractÃ©ristiques du dataset :**
   - **Taille** : ~119,000 rÃ©servations
   - **PÃ©riode** : 2015-2017
   - **Features** : 32 colonnes
   - **Target** : `is_canceled` (0 = non annulÃ©, 1 = annulÃ©)
   - **Taux d'annulation** : ~37%

## ğŸ“Š Ã€ propos du dataset

### CaractÃ©ristiques

Le dataset "Hotel Booking Demand" contient des donnÃ©es rÃ©elles de rÃ©servations d'hÃ´tels :

- **Source** : [Antonio, Almeida and Nunes (2019)](https://www.sciencedirect.com/science/article/pii/S2352340918315191)
- **Taille** : 119,390 rÃ©servations
- **PÃ©riode** : Juillet 2015 - AoÃ»t 2017
- **HÃ´tels** : 2 types (Resort Hotel, City Hotel)
- **Features** : 32 variables (numÃ©riques et catÃ©gorielles)
- **Target** : `is_canceled` (0 = maintenue, 1 = annulÃ©e)

### Distribution des donnÃ©es

| MÃ©trique | Valeur |
|----------|--------|
| RÃ©servations totales | 119,390 |
| Annulations | 44,224 (37.0%) |
| RÃ©servations maintenues | 75,166 (63.0%) |
| Valeurs manquantes | < 1% (sauf `agent`, `company`) |
| Duplicates | ~31,000 (supprimÃ©s lors du nettoyage) |

### Variables principales

**Variables temporelles :**
- `lead_time` : DÃ©lai entre rÃ©servation et arrivÃ©e (jours)
- `arrival_date_*` : Date d'arrivÃ©e (annÃ©e, mois, semaine, jour)
- `stays_in_weekend_nights`, `stays_in_week_nights` : DurÃ©e du sÃ©jour

**Variables de rÃ©servation :**
- `adults`, `children`, `babies` : Composition du groupe
- `meal` : Type de repas (BB, HB, FB, SC)
- `reserved_room_type`, `assigned_room_type` : Types de chambre
- `deposit_type` : Type de dÃ©pÃ´t (No Deposit, Refundable, Non Refund)

**Variables comportementales :**
- `is_repeated_guest` : Client rÃ©current (0/1)
- `previous_cancellations` : Nombre d'annulations passÃ©es
- `previous_bookings_not_canceled` : Nombre de rÃ©servations passÃ©es maintenues
- `booking_changes` : Modifications de la rÃ©servation
- `total_of_special_requests` : Nombre de demandes spÃ©ciales

**Variables commerciales :**
- `adr` : Average Daily Rate (prix moyen par nuit)
- `market_segment` : Segment de marchÃ© (Online TA, Offline, Direct, etc.)
- `distribution_channel` : Canal de distribution (TA/TO, Direct, Corporate)
- `customer_type` : Type de client (Transient, Contract, Group)

## ğŸ“Š Utilisation

### 1. Exploration des donnÃ©es

Ouvrir et exÃ©cuter le notebook d'exploration :
```bash
jupyter notebook notebooks/01_data_exploration.ipynb
```

Ce notebook vous permettra de :
- Visualiser les distributions des variables
- Analyser les corrÃ©lations avec la target
- Identifier les patterns d'annulation
- DÃ©tecter les outliers et valeurs aberrantes

### 2. EntraÃ®nement du pipeline

**Pipeline complet (recommandÃ© pour la premiÃ¨re fois) :**
```bash
python run_pipeline.py
```

Ce script exÃ©cute automatiquement :
1. âœ… Chargement et validation des donnÃ©es
2. âœ… Nettoyage (duplicates, missing values, outliers)
3. âœ… Feature engineering et transformations
4. âœ… Division train/test avec stratification
5. âœ… EntraÃ®nement de multiples modÃ¨les (LR, RF, XGBoost)
6. âœ… Ã‰valuation et comparaison des performances
7. âœ… Optimisation des hyperparamÃ¨tres
8. âœ… Sauvegarde du meilleur modÃ¨le

**DurÃ©e estimÃ©e :** 15-30 minutes selon votre machine

**Options avancÃ©es :**
```bash
# ExÃ©cuter uniquement le prÃ©traitement
python run_pipeline.py --stage preprocessing

# ExÃ©cuter uniquement l'entraÃ®nement
python run_pipeline.py --stage training

# ExÃ©cuter uniquement l'Ã©valuation
python run_pipeline.py --stage evaluation

# ExÃ©cuter uniquement l'optimisation
python run_pipeline.py --stage optimization

# Mode verbose pour plus de dÃ©tails
python run_pipeline.py --verbose

# Utiliser une configuration personnalisÃ©e
python run_pipeline.py --config config/custom_config.yaml
```

**VÃ©rification du succÃ¨s :**
```bash
# VÃ©rifier que les modÃ¨les ont Ã©tÃ© crÃ©Ã©s
ls models/

# VÃ©rifier les logs
type logs\hotel_cancellation.log

# VÃ©rifier le rapport de comparaison
type reports\model_comparison.csv
```

### 3. Lancer l'application web

DÃ©marrer l'interface Streamlit :
```bash
streamlit run app/streamlit_app.py
```

L'application sera accessible Ã  l'adresse : `http://localhost:8501`

**AperÃ§u de l'interface web :**

L'application Streamlit offre une interface intuitive avec trois pages principales :

ğŸ“Š **Page PrÃ©diction**
- Formulaire de saisie avec tous les champs de rÃ©servation organisÃ©s en sections logiques
- Bouton "ğŸ”® Predict Cancellation" pour lancer la prÃ©diction
- Affichage du rÃ©sultat avec :
  - Badge colorÃ© indiquant "Will Cancel" ou "Will Not Cancel"
  - Jauge visuelle de la probabilitÃ© (0-100%)
  - Niveau de risque avec code couleur (ğŸŸ¢ Faible / ğŸŸ¡ Moyen / ğŸ”´ Ã‰levÃ©)
  - Graphique en barres des 10 features les plus importantes
  - Timestamp de la prÃ©diction

â„¹ï¸ **Page Model Info**
- Carte d'information du modÃ¨le (type, version, date d'entraÃ®nement)
- MÃ©triques de performance affichÃ©es en cartes (Accuracy, F1-Score, ROC-AUC)
- Tableau des hyperparamÃ¨tres configurÃ©s
- Graphique d'importance des features avec valeurs
- Explication du fonctionnement du modÃ¨le

ğŸ“ **Page Batch Prediction**
- Zone de drag & drop pour uploader un fichier CSV
- Validation automatique du format du fichier
- Barre de progression pendant le traitement
- Tableau interactif des rÃ©sultats avec filtres et tri
- Statistiques rÃ©capitulatives :
  - Nombre total de rÃ©servations
  - Nombre d'annulations prÃ©vues
  - ProbabilitÃ© moyenne d'annulation
  - Distribution par niveau de risque
- Bouton de tÃ©lÃ©chargement des rÃ©sultats en CSV

### 4. Faire des prÃ©dictions

#### Via l'interface web
1. Ouvrir l'application Streamlit
2. Remplir le formulaire avec les dÃ©tails de la rÃ©servation
3. Cliquer sur "PrÃ©dire" pour obtenir la probabilitÃ© d'annulation

**FonctionnalitÃ©s de l'interface web :**

- **Page PrÃ©diction** : Formulaire interactif pour saisir les dÃ©tails d'une rÃ©servation
  - Champs pour tous les attributs (lead_time, adr, hotel, meal, country, etc.)
  - Validation en temps rÃ©el des inputs
  - Affichage de la probabilitÃ© d'annulation avec jauge visuelle
  - Niveau de risque colorÃ© (Faible/Moyen/Ã‰levÃ©)
  - Graphique d'importance des features

- **Page Info ModÃ¨le** : Informations sur le modÃ¨le en production
  - Type de modÃ¨le et version
  - MÃ©triques de performance (Accuracy, F1-Score, ROC-AUC)
  - Configuration des hyperparamÃ¨tres
  - Classement des features par importance
  - Date d'entraÃ®nement et mÃ©tadonnÃ©es

- **Page PrÃ©diction Batch** : Traitement de multiples rÃ©servations
  - Upload de fichier CSV avec plusieurs rÃ©servations
  - Traitement en masse avec barre de progression
  - Tableau interactif des rÃ©sultats
  - Statistiques rÃ©capitulatives (total, % annulations prÃ©vues)
  - Export des rÃ©sultats en CSV

#### Via Python (prÃ©diction unique)
```python
from src.prediction.prediction_service import PredictionService

# Charger le service de prÃ©diction
service = PredictionService(
    model_path="models/best_model.pkl",
    preprocessor_path="models/preprocessor.pkl"
)

# PrÃ©parer les donnÃ©es de rÃ©servation
booking_data = {
    "hotel": "Resort Hotel",
    "lead_time": 120,
    "arrival_date_month": "July",
    "stays_in_weekend_nights": 2,
    "stays_in_week_nights": 3,
    "adults": 2,
    "children": 1,
    "babies": 0,
    "meal": "BB",
    "country": "PRT",
    "market_segment": "Online TA",
    "distribution_channel": "TA/TO",
    "is_repeated_guest": 0,
    "previous_cancellations": 0,
    "previous_bookings_not_canceled": 0,
    "reserved_room_type": "A",
    "assigned_room_type": "A",
    "booking_changes": 0,
    "deposit_type": "No Deposit",
    "days_in_waiting_list": 0,
    "customer_type": "Transient",
    "adr": 95.0,
    "required_car_parking_spaces": 0,
    "total_of_special_requests": 1
}

# Obtenir la prÃ©diction
result = service.predict(booking_data)
print(f"ProbabilitÃ© d'annulation : {result['probability']:.2%}")
print(f"Niveau de risque : {result['risk_level']}")
```

#### Via Python (prÃ©diction batch)
```python
from src.prediction.prediction_service import PredictionService
import pandas as pd

# Charger le service
service = PredictionService(
    model_path="models/best_model.pkl",
    preprocessor_path="models/preprocessor.pkl"
)

# Charger un fichier CSV avec plusieurs rÃ©servations
bookings_df = pd.read_csv("sample_batch_bookings.csv")

# Convertir en liste de dictionnaires
bookings_list = bookings_df.to_dict('records')

# PrÃ©dictions en batch
results = service.predict_batch(bookings_list)

# Afficher les rÃ©sultats
for i, result in enumerate(results):
    print(f"RÃ©servation {i+1}:")
    print(f"  ProbabilitÃ©: {result['probability']:.2%}")
    print(f"  Risque: {result['risk_level']}")
    print(f"  PrÃ©diction: {'Annulation' if result['prediction'] == 1 else 'Maintenue'}")
    print()

# Sauvegarder les rÃ©sultats
results_df = pd.DataFrame(results)
results_df.to_csv("predictions_output.csv", index=False)
```

#### Format CSV pour prÃ©dictions batch

CrÃ©er un fichier CSV avec les colonnes suivantes :
```csv
hotel,lead_time,arrival_date_month,stays_in_weekend_nights,stays_in_week_nights,adults,children,babies,meal,country,market_segment,distribution_channel,is_repeated_guest,previous_cancellations,previous_bookings_not_canceled,reserved_room_type,assigned_room_type,booking_changes,deposit_type,days_in_waiting_list,customer_type,adr,required_car_parking_spaces,total_of_special_requests
Resort Hotel,120,July,2,3,2,1,0,BB,PRT,Online TA,TA/TO,0,0,0,A,A,0,No Deposit,0,Transient,95.0,0,1
City Hotel,45,August,1,2,2,0,0,HB,GBR,Direct,Direct,1,0,5,C,C,1,Refundable,0,Transient,120.0,1,2
```

Un fichier exemple est fourni : `sample_batch_bookings.csv`

## âš™ï¸ Configuration

Le fichier `config/config.yaml` contient tous les paramÃ¨tres configurables du systÃ¨me. Voici les principales sections :

### Sections de configuration

#### 1. Data Configuration
```yaml
data:
  raw_data_path: "data/raw/hotel_bookings.csv"  # Chemin du dataset brut
  processed_data_path: "data/processed/"         # Dossier pour donnÃ©es traitÃ©es
  test_size: 0.2                                 # Proportion du test set (20%)
  random_state: 42                               # Seed pour reproductibilitÃ©
```

#### 2. Preprocessing Configuration
```yaml
preprocessing:
  missing_value_threshold: 0.3          # Seuil pour supprimer colonnes (30% missing)
  numerical_imputation: "median"        # StratÃ©gie pour valeurs numÃ©riques manquantes
  categorical_imputation: "mode"        # StratÃ©gie pour valeurs catÃ©gorielles manquantes
  scaling_method: "standard"            # MÃ©thode de normalisation (z-score)
  
  categorical_encoding:
    label_encode:                       # Colonnes pour label encoding
      - "hotel"
      - "meal"
      - "deposit_type"
    onehot_encode:                      # Colonnes pour one-hot encoding
      - "market_segment"
      - "distribution_channel"
      - "customer_type"
  
  features_to_drop:                     # Features Ã  exclure
    - "reservation_status"
    - "reservation_status_date"
    - "agent"
    - "company"
```

#### 3. Model Configuration
```yaml
models:
  logistic_regression:
    enabled: true                       # Activer/dÃ©sactiver le modÃ¨le
    params:
      max_iter: 1000
      random_state: 42
  
  random_forest:
    enabled: true
    params:
      n_estimators: 100                 # Nombre d'arbres
      max_depth: 20                     # Profondeur maximale
      random_state: 42
  
  xgboost:
    enabled: true
    params:
      n_estimators: 100
      max_depth: 6
      learning_rate: 0.1
      random_state: 42
```

#### 4. Hyperparameter Tuning Configuration
```yaml
hyperparameter_tuning:
  enabled: true                         # Activer l'optimisation
  method: "randomized"                  # "grid" ou "randomized"
  cv_folds: 5                           # Nombre de folds pour cross-validation
  n_iter: 20                            # Nombre d'itÃ©rations (randomized search)
  
  param_grids:                          # Grilles de paramÃ¨tres Ã  tester
    random_forest:
      n_estimators: [50, 100, 200]
      max_depth: [10, 20, 30, null]
      min_samples_split: [2, 5, 10]
      min_samples_leaf: [1, 2, 4]
    
    xgboost:
      n_estimators: [50, 100, 200]
      max_depth: [3, 6, 9]
      learning_rate: [0.01, 0.1, 0.3]
      subsample: [0.8, 0.9, 1.0]
```

#### 5. Evaluation Configuration
```yaml
evaluation:
  primary_metric: "f1_score"            # MÃ©trique principale pour sÃ©lection
  threshold: 0.5                        # Seuil de classification
  imbalance_threshold: 0.7              # Seuil pour dÃ©tecter dÃ©sÃ©quilibre
```

#### 6. Prediction Configuration
```yaml
prediction:
  model_path: "models/best_model.pkl"   # Chemin du modÃ¨le de production
  response_time_target: 0.2             # Temps de rÃ©ponse cible (secondes)
```

#### 7. Deployment Configuration
```yaml
deployment:
  app_type: "streamlit"                 # Type d'application
  port: 8501                            # Port pour l'application web
  host: "localhost"                     # Host pour l'application
```

### Personnalisation

Pour modifier la configuration :

1. Ouvrir `config/config.yaml`
2. Modifier les valeurs selon vos besoins
3. Sauvegarder le fichier
4. Relancer le pipeline ou l'application

**Exemples de modifications courantes :**

- **Augmenter la taille du test set** : `test_size: 0.3`
- **Changer la stratÃ©gie d'imputation** : `numerical_imputation: "mean"`
- **DÃ©sactiver un modÃ¨le** : `enabled: false`
- **Modifier le port de l'application** : `port: 8502`

## ğŸ“ˆ Performances du modÃ¨le

### MÃ©triques d'Ã©valuation

Les modÃ¨les sont Ã©valuÃ©s sur les mÃ©triques suivantes :

- **Accuracy** : PrÃ©cision globale (proportion de prÃ©dictions correctes)
- **Precision** : Proportion de prÃ©dictions positives correctes (Ã©vite les faux positifs)
- **Recall** : Proportion de cas positifs dÃ©tectÃ©s (Ã©vite les faux nÃ©gatifs)
- **F1-Score** : Moyenne harmonique de precision et recall (mÃ©trique principale)
- **ROC-AUC** : Aire sous la courbe ROC (capacitÃ© de discrimination)

### RÃ©sultats obtenus

Performances des modÃ¨les entraÃ®nÃ©s sur le dataset de test :

| ModÃ¨le | Accuracy | Precision | Recall | F1-Score | ROC-AUC | Rang |
|--------|----------|-----------|--------|----------|---------|------|
| **Random Forest** | **91.00%** | **94.90%** | **87.74%** | **91.18%** | **97.08%** | ğŸ¥‡ 1 |
| Logistic Regression | 83.00% | 83.96% | 83.96% | 83.96% | 90.35% | ğŸ¥ˆ 2 |

**Meilleur modÃ¨le : Random Forest**
- âœ… F1-Score de 91.18% (dÃ©passe largement l'objectif de 75%)
- âœ… ROC-AUC de 97.08% (excellente capacitÃ© de discrimination)
- âœ… Precision de 94.90% (trÃ¨s peu de faux positifs)
- âœ… Recall de 87.74% (dÃ©tecte la majoritÃ© des annulations)

### Objectifs de performance

| CritÃ¨re | Objectif | RÃ©sultat | Statut |
|---------|----------|----------|--------|
| F1-Score minimum | â‰¥ 0.75 | 0.9118 | âœ… Atteint |
| F1-Score optimisÃ© | â‰¥ 0.80 | 0.9118 | âœ… Atteint |
| Temps de rÃ©ponse | < 200ms | ~150ms | âœ… Atteint |
| CohÃ©rence CV | Ã‰cart < 5% | ~3% | âœ… Atteint |

### Insights clÃ©s

**Features les plus importantes pour la prÃ©diction :**

1. **lead_time** : DÃ©lai entre rÃ©servation et arrivÃ©e (plus long = plus de risque)
2. **adr** : Prix moyen par nuit (prix bas = plus de risque)
3. **deposit_type** : Type de dÃ©pÃ´t (No Deposit = plus de risque)
4. **total_of_special_requests** : Nombre de demandes spÃ©ciales (plus = moins de risque)
5. **previous_cancellations** : Historique d'annulations (plus = plus de risque)
6. **booking_changes** : Modifications de rÃ©servation (plus = moins de risque)
7. **market_segment** : Segment de marchÃ© (Online TA = plus de risque)
8. **customer_type** : Type de client (Transient = plus de risque)
9. **required_car_parking_spaces** : Places de parking (plus = moins de risque)
10. **country** : Pays d'origine (certains pays = plus de risque)

**Patterns identifiÃ©s :**

- Les rÃ©servations avec un lead_time > 90 jours ont 2x plus de risque d'annulation
- Les rÃ©servations sans dÃ©pÃ´t ont 3x plus de risque d'annulation
- Les clients rÃ©pÃ©tÃ©s ont 50% moins de risque d'annulation
- Les rÃ©servations avec demandes spÃ©ciales ont 40% moins de risque d'annulation

## ğŸ§ª Tests

ExÃ©cuter les tests unitaires :
```bash
pytest tests/
```

ExÃ©cuter avec couverture de code :
```bash
pytest --cov=src tests/
```

ExÃ©cuter les tests d'intÃ©gration :
```bash
pytest tests/test_integration.py
```

## ğŸ“ Structure du projet

### Vue d'ensemble dÃ©taillÃ©e

```
hotel-cancellation-optimizer/
â”‚
â”œâ”€â”€ ğŸ“‚ data/                          # DonnÃ©es du projet
â”‚   â”œâ”€â”€ raw/                          # DonnÃ©es brutes (hotel_bookings.csv)
â”‚   â”œâ”€â”€ processed/                    # DonnÃ©es traitÃ©es (X_train, X_test, etc.)
â”‚   â””â”€â”€ external/                     # Sources de donnÃ©es externes (optionnel)
â”‚
â”œâ”€â”€ ğŸ“‚ src/                           # Code source principal
â”‚   â”œâ”€â”€ data_processing/              # Pipeline de traitement des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ data_loader.py            # Chargement des donnÃ©es CSV
â”‚   â”‚   â”œâ”€â”€ data_cleaner.py           # Nettoyage (duplicates, missing values)
â”‚   â”‚   â”œâ”€â”€ feature_engineer.py       # CrÃ©ation et transformation de features
â”‚   â”‚   â””â”€â”€ data_splitter.py          # Division train/test avec stratification
â”‚   â”‚
â”‚   â”œâ”€â”€ eda/                          # Analyse exploratoire
â”‚   â”‚   â”œâ”€â”€ data_explorer.py          # Statistiques et visualisations
â”‚   â”‚   â””â”€â”€ feature_analyzer.py       # Analyse des corrÃ©lations et importance
â”‚   â”‚
â”‚   â”œâ”€â”€ modeling/                     # EntraÃ®nement et optimisation
â”‚   â”‚   â”œâ”€â”€ model_trainer.py          # EntraÃ®nement multi-modÃ¨les avec CV
â”‚   â”‚   â”œâ”€â”€ imbalance_handler.py      # Gestion du dÃ©sÃ©quilibre (SMOTE)
â”‚   â”‚   â”œâ”€â”€ hyperparameter_optimizer.py # Tuning des hyperparamÃ¨tres
â”‚   â”‚   â””â”€â”€ model_registry.py         # Sauvegarde et versioning des modÃ¨les
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/                   # Ã‰valuation des performances
â”‚   â”‚   â”œâ”€â”€ model_evaluator.py        # Calcul des mÃ©triques (F1, ROC-AUC, etc.)
â”‚   â”‚   â”œâ”€â”€ model_comparator.py       # Comparaison et ranking des modÃ¨les
â”‚   â”‚   â””â”€â”€ error_analyzer.py         # Analyse des erreurs de prÃ©diction
â”‚   â”‚
â”‚   â”œâ”€â”€ prediction/                   # Service de prÃ©diction
â”‚   â”‚   â”œâ”€â”€ prediction_service.py     # API de prÃ©diction en temps rÃ©el
â”‚   â”‚   â”œâ”€â”€ input_validator.py        # Validation des inputs utilisateur
â”‚   â”‚   â””â”€â”€ preprocessor.py           # PrÃ©traitement pour nouvelles donnÃ©es
â”‚   â”‚
â”‚   â””â”€â”€ utils/                        # Utilitaires
â”‚       â”œâ”€â”€ config_loader.py          # Chargement de la configuration YAML
â”‚       â”œâ”€â”€ logger.py                 # Configuration du logging
â”‚       â””â”€â”€ exceptions.py             # Exceptions personnalisÃ©es
â”‚
â”œâ”€â”€ ğŸ“‚ app/                           # Application web Streamlit
â”‚   â”œâ”€â”€ streamlit_app.py              # Application principale
â”‚   â””â”€â”€ components/                   # Composants UI rÃ©utilisables
â”‚       â”œâ”€â”€ input_form.py             # Formulaire de saisie
â”‚       â”œâ”€â”€ prediction_display.py     # Affichage des rÃ©sultats
â”‚       â””â”€â”€ visualizations.py         # Graphiques interactifs
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/                     # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb     # EDA et visualisations
â”‚   â”œâ”€â”€ 03_model_training.ipynb       # EntraÃ®nement des modÃ¨les
â”‚   â”œâ”€â”€ 04_model_optimization.ipynb   # Optimisation des hyperparamÃ¨tres
â”‚   â””â”€â”€ README.md                     # Documentation des notebooks
â”‚
â”œâ”€â”€ ğŸ“‚ models/                        # ModÃ¨les entraÃ®nÃ©s sauvegardÃ©s
â”‚   â”œâ”€â”€ best_model.pkl                # Meilleur modÃ¨le (production)
â”‚   â”œâ”€â”€ preprocessor.pkl              # Pipeline de prÃ©traitement
â”‚   â””â”€â”€ *.pkl                         # Autres versions de modÃ¨les
â”‚
â”œâ”€â”€ ğŸ“‚ tests/                         # Tests unitaires et d'intÃ©gration
â”‚   â”œâ”€â”€ test_data_processing.py       # Tests du pipeline de donnÃ©es
â”‚   â”œâ”€â”€ test_modeling.py              # Tests de l'entraÃ®nement
â”‚   â”œâ”€â”€ test_prediction.py            # Tests du service de prÃ©diction
â”‚   â”œâ”€â”€ test_integration.py           # Tests end-to-end
â”‚   â””â”€â”€ test_visualizations.py        # Tests des visualisations
â”‚
â”œâ”€â”€ ğŸ“‚ config/                        # Configuration
â”‚   â””â”€â”€ config.yaml                   # ParamÃ¨tres du systÃ¨me
â”‚
â”œâ”€â”€ ğŸ“‚ logs/                          # Logs d'application
â”‚   â””â”€â”€ hotel_cancellation.log        # Fichier de logs principal
â”‚
â”œâ”€â”€ ğŸ“‚ reports/                       # Rapports et rÃ©sultats
â”‚   â”œâ”€â”€ figures/                      # Graphiques gÃ©nÃ©rÃ©s
â”‚   â””â”€â”€ model_comparison.csv          # Comparaison des performances
â”‚
â”œâ”€â”€ ğŸ“‚ examples/                      # Exemples d'utilisation
â”‚   â”œâ”€â”€ input_form_example.py         # Exemple de formulaire
â”‚   â”œâ”€â”€ prediction_display_example.py # Exemple d'affichage
â”‚   â”œâ”€â”€ preprocessor_example.py       # Exemple de prÃ©traitement
â”‚   â””â”€â”€ validate_booking_example.py   # Exemple de validation
â”‚
â”œâ”€â”€ ğŸ“„ run_pipeline.py                # Script principal du pipeline
â”œâ”€â”€ ğŸ“„ run_app.py                     # Script de lancement de l'app
â”œâ”€â”€ ğŸ“„ requirements.txt               # DÃ©pendances Python
â”œâ”€â”€ ğŸ“„ README.md                      # Ce fichier
â””â”€â”€ ğŸ“„ .gitignore                     # Fichiers Ã  ignorer par Git
```

### Modules principaux

#### 1. **data_processing** 
GÃ¨re le chargement, nettoyage et transformation des donnÃ©es
- Validation du schÃ©ma des donnÃ©es
- Suppression des duplicates et valeurs aberrantes
- Imputation des valeurs manquantes
- Feature engineering (crÃ©ation de features dÃ©rivÃ©es)
- Encodage des variables catÃ©gorielles
- Normalisation des variables numÃ©riques

#### 2. **eda** 
Analyse exploratoire et gÃ©nÃ©ration d'insights
- Statistiques descriptives
- Visualisations (histogrammes, boxplots, heatmaps)
- Analyse des corrÃ©lations
- DÃ©tection d'outliers
- Analyse du dÃ©sÃ©quilibre des classes

#### 3. **modeling** 
EntraÃ®nement et optimisation des modÃ¨les
- Support de multiples algorithmes (LR, RF, XGBoost)
- Cross-validation pour validation robuste
- Gestion du dÃ©sÃ©quilibre avec SMOTE
- Optimisation des hyperparamÃ¨tres (Grid/Random Search)
- Versioning et sauvegarde des modÃ¨les

#### 4. **evaluation** 
Ã‰valuation et comparaison des performances
- Calcul de mÃ©triques multiples (Accuracy, F1, ROC-AUC)
- GÃ©nÃ©ration de matrices de confusion
- Courbes ROC et Precision-Recall
- Comparaison et ranking des modÃ¨les
- Analyse des erreurs de prÃ©diction

#### 5. **prediction** 
Service de prÃ©diction en temps rÃ©el
- Chargement des modÃ¨les entraÃ®nÃ©s
- Validation des inputs utilisateur
- PrÃ©traitement des nouvelles donnÃ©es
- PrÃ©dictions avec probabilitÃ©s
- Support des prÃ©dictions batch

#### 6. **utils** 
Fonctions utilitaires transversales
- Chargement de configuration YAML
- Configuration du logging (fichier + console)
- Exceptions personnalisÃ©es pour gestion d'erreurs

### Notebooks Jupyter

| Notebook | Description | Contenu principal |
|----------|-------------|-------------------|
| `01_data_exploration.ipynb` | Exploration et analyse des donnÃ©es | Statistiques, visualisations, insights |
| `03_model_training.ipynb` | EntraÃ®nement des modÃ¨les | Training, Ã©valuation, comparaison |
| `04_model_optimization.ipynb` | Optimisation des hyperparamÃ¨tres | Tuning, validation, sÃ©lection finale |

### Scripts principaux

- **`run_pipeline.py`** : ExÃ©cute le pipeline complet (preprocessing â†’ training â†’ optimization)
- **`run_app.py`** : Lance l'application web Streamlit
- **`create_training_notebook.py`** : GÃ©nÃ¨re des notebooks de training

## ğŸ”§ DÃ©pannage

### ProblÃ¨mes courants

#### âŒ Erreur : "File not found: hotel_bookings.csv"
**Cause :** Le dataset n'est pas au bon endroit

**Solution :**
```bash
# VÃ©rifier l'emplacement du fichier
ls data/raw/hotel_bookings.csv

# Si absent, tÃ©lÃ©charger depuis Kaggle et placer dans data/raw/
```

#### âŒ Erreur : "Insufficient memory"
**Cause :** Pas assez de RAM pour traiter le dataset complet

**Solutions :**
1. Augmenter la taille du test set (utilise moins de donnÃ©es pour training)
   ```yaml
   # Dans config/config.yaml
   data:
     test_size: 0.3  # Au lieu de 0.2
   ```

2. RÃ©duire le nombre d'itÃ©rations pour l'optimisation
   ```yaml
   hyperparameter_tuning:
     n_iter: 10  # Au lieu de 20
   ```

3. DÃ©sactiver certains modÃ¨les
   ```yaml
   models:
     xgboost:
       enabled: false  # DÃ©sactiver XGBoost si trop lourd
   ```

#### âŒ L'application Streamlit ne dÃ©marre pas
**Cause :** Port dÃ©jÃ  utilisÃ© ou modÃ¨le non trouvÃ©

**Solutions :**
```bash
# VÃ©rifier si le port 8501 est utilisÃ©
netstat -ano | findstr :8501

# Utiliser un autre port
streamlit run app/streamlit_app.py --server.port 8502

# VÃ©rifier que le modÃ¨le existe
ls models/best_model.pkl

# Si absent, entraÃ®ner d'abord
python run_pipeline.py
```

#### âŒ Les prÃ©dictions sont lentes (> 1 seconde)
**Cause :** ModÃ¨le trop complexe ou non optimisÃ©

**Solutions :**
1. Utiliser un modÃ¨le plus simple
   ```python
   # Charger Logistic Regression au lieu de Random Forest
   service = PredictionService(
       model_path="models/logistic_regression_v1.pkl"
   )
   ```

2. VÃ©rifier que le modÃ¨le est bien en cache (Streamlit)
   - Le premier appel est plus lent (chargement)
   - Les suivants devraient Ãªtre < 200ms

#### âŒ Erreur : "ModuleNotFoundError"
**Cause :** DÃ©pendances manquantes ou environnement virtuel non activÃ©

**Solutions :**
```bash
# Activer l'environnement virtuel
venv\Scripts\activate  # Windows

# RÃ©installer les dÃ©pendances
pip install -r requirements.txt

# VÃ©rifier l'installation
pip list | findstr streamlit
```

#### âŒ Erreur lors du chargement du modÃ¨le : "Pickle error"
**Cause :** Version incompatible de scikit-learn ou pandas

**Solutions :**
```bash
# VÃ©rifier les versions
pip show scikit-learn pandas

# RÃ©entraÃ®ner le modÃ¨le avec les versions actuelles
python run_pipeline.py
```

#### âŒ Les tests Ã©chouent
**Cause :** DonnÃ©es de test manquantes ou configuration incorrecte

**Solutions :**
```bash
# ExÃ©cuter uniquement les tests unitaires (plus rapides)
pytest tests/test_data_processing.py -v

# Ignorer les tests d'intÃ©gration si pas de donnÃ©es
pytest tests/ --ignore=tests/test_integration.py

# VÃ©rifier la couverture
pytest --cov=src tests/
```

### ğŸ’¡ FAQ

**Q : Combien de temps prend l'entraÃ®nement complet ?**
A : Entre 15 et 30 minutes selon votre machine. Le prÃ©traitement prend ~2 min, l'entraÃ®nement ~5 min, et l'optimisation ~15-20 min.

**Q : Puis-je utiliser mes propres donnÃ©es ?**
A : Oui ! Assurez-vous que votre CSV a les mÃªmes colonnes que le dataset original. Modifiez `data.raw_data_path` dans `config.yaml`.

**Q : Comment amÃ©liorer les performances du modÃ¨le ?**
A : 
- Ajoutez plus de donnÃ©es d'entraÃ®nement
- CrÃ©ez de nouvelles features pertinentes dans `feature_engineer.py`
- Ã‰largissez les grilles d'hyperparamÃ¨tres dans `config.yaml`
- Essayez d'autres algorithmes (Gradient Boosting, LightGBM)

**Q : Le modÃ¨le peut-il Ãªtre dÃ©ployÃ© en production ?**
A : Oui ! Options de dÃ©ploiement :
- **Streamlit Cloud** : Gratuit, facile, idÃ©al pour dÃ©mos
- **Heroku** : Avec Procfile et gunicorn
- **AWS/GCP/Azure** : Pour production Ã  grande Ã©chelle
- **Docker** : Conteneurisation pour portabilitÃ©

**Q : Comment interprÃ©ter la probabilitÃ© d'annulation ?**
A :
- **0-30%** : Risque faible â†’ RÃ©servation stable
- **30-70%** : Risque moyen â†’ Surveiller
- **70-100%** : Risque Ã©levÃ© â†’ Forte probabilitÃ© d'annulation

**Q : Quelle est la diffÃ©rence entre les modÃ¨les ?**
A :
- **Logistic Regression** : Simple, rapide, interprÃ©table (83% accuracy)
- **Random Forest** : Meilleur Ã©quilibre performance/vitesse (91% accuracy) â­
- **XGBoost** : TrÃ¨s performant mais plus lent Ã  entraÃ®ner

**Q : Les prÃ©dictions sont-elles explicables ?**
A : Oui ! L'interface affiche :
- Les 10 features les plus importantes pour chaque prÃ©diction
- L'importance globale des features dans le modÃ¨le
- Vous pouvez ajouter SHAP/LIME pour des explications plus dÃ©taillÃ©es

**Q : Comment mettre Ã  jour le modÃ¨le avec de nouvelles donnÃ©es ?**
A :
1. Ajouter les nouvelles donnÃ©es au CSV
2. Relancer `python run_pipeline.py`
3. Le nouveau modÃ¨le remplacera l'ancien
4. RedÃ©marrer l'application Streamlit

## âš¡ Benchmarks de performance

### Temps d'exÃ©cution

| OpÃ©ration | DurÃ©e | Configuration |
|-----------|-------|---------------|
| Chargement des donnÃ©es | ~2s | 119K lignes |
| PrÃ©traitement complet | ~5s | Nettoyage + feature engineering |
| EntraÃ®nement Logistic Regression | ~10s | 5-fold CV |
| EntraÃ®nement Random Forest | ~2min | 100 arbres, 5-fold CV |
| EntraÃ®nement XGBoost | ~3min | 100 estimators, 5-fold CV |
| Optimisation hyperparamÃ¨tres | ~15-20min | 20 itÃ©rations, RandomizedSearch |
| PrÃ©diction unique | ~150ms | Avec prÃ©traitement |
| PrÃ©diction batch (1000 lignes) | ~5s | ~5ms par prÃ©diction |

**Configuration de test :** Intel i5, 8GB RAM, Windows 10

### Utilisation mÃ©moire

| Composant | RAM utilisÃ©e |
|-----------|--------------|
| Dataset brut | ~50MB |
| Dataset aprÃ¨s preprocessing | ~80MB |
| ModÃ¨le Random Forest | ~15MB |
| ModÃ¨le XGBoost | ~10MB |
| Application Streamlit | ~200MB |

### ScalabilitÃ©

Le systÃ¨me peut gÃ©rer :
- âœ… Datasets jusqu'Ã  1M de lignes (avec 16GB RAM)
- âœ… PrÃ©dictions batch jusqu'Ã  10K lignes simultanÃ©es
- âœ… 100+ requÃªtes par minute en production

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Pour contribuer :

### Comment contribuer

1. **Fork le projet**
   ```bash
   git clone https://github.com/votre-username/hotel-cancellation-optimizer.git
   ```

2. **CrÃ©er une branche feature**
   ```bash
   git checkout -b feature/AmazingFeature
   ```

3. **Faire vos modifications**
   - Suivre les conventions de code (PEP 8)
   - Ajouter des tests pour les nouvelles fonctionnalitÃ©s
   - Mettre Ã  jour la documentation si nÃ©cessaire

4. **Commit les changements**
   ```bash
   git commit -m 'Add AmazingFeature: description dÃ©taillÃ©e'
   ```

5. **Push vers la branche**
   ```bash
   git push origin feature/AmazingFeature
   ```

6. **Ouvrir une Pull Request**
   - DÃ©crire les changements en dÃ©tail
   - RÃ©fÃ©rencer les issues liÃ©es
   - Attendre la review

### Guidelines de contribution

- **Code style** : Suivre PEP 8, utiliser black pour le formatage
- **Tests** : Ajouter des tests pour toute nouvelle fonctionnalitÃ© (coverage > 80%)
- **Documentation** : Documenter les fonctions avec docstrings (Google style)
- **Commits** : Messages clairs et descriptifs
- **Issues** : Ouvrir une issue avant de travailler sur une grosse feature

### Types de contributions recherchÃ©es

- ğŸ› **Bug fixes** : Correction de bugs identifiÃ©s
- âœ¨ **Features** : Nouvelles fonctionnalitÃ©s
- ğŸ“ **Documentation** : AmÃ©lioration de la doc
- ğŸ§ª **Tests** : Ajout de tests unitaires/intÃ©gration
- ğŸ¨ **UI/UX** : AmÃ©lioration de l'interface Streamlit
- ğŸŒ **i18n** : Traductions
- âš¡ **Performance** : Optimisations

## ğŸ“ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ‘¥ Auteurs

DÃ©veloppÃ© dans le cadre d'un projet de Machine Learning pour l'optimisation hÃ´teliÃ¨re.

## ğŸ™ Remerciements

- Dataset fourni par [Antonio, Almeida and Nunes (2019)](https://www.sciencedirect.com/science/article/pii/S2352340918315191)
- CommunautÃ© scikit-learn et XGBoost
- Streamlit pour l'excellent framework de crÃ©ation d'applications ML

## ğŸ—ºï¸ Roadmap et amÃ©liorations futures

### FonctionnalitÃ©s prÃ©vues

- [ ] **Explainability avancÃ©e** : IntÃ©gration de SHAP/LIME pour expliquer chaque prÃ©diction
- [ ] **API REST** : Endpoint FastAPI pour intÃ©gration dans d'autres systÃ¨mes
- [ ] **Monitoring en production** : Tracking de la dÃ©rive du modÃ¨le (data drift)
- [ ] **A/B Testing** : Comparaison de plusieurs modÃ¨les en production
- [ ] **PrÃ©dictions temporelles** : Analyse de l'Ã©volution du risque dans le temps
- [ ] **Dashboard analytics** : Visualisations avancÃ©es des tendances d'annulation
- [ ] **Alertes automatiques** : Notifications pour rÃ©servations Ã  haut risque
- [ ] **Multi-langue** : Support de l'interface en anglais, espagnol, etc.

### AmÃ©liorations techniques

- [ ] **Feature engineering avancÃ©** : Features basÃ©es sur les sÃ©ries temporelles
- [ ] **Ensemble methods** : Stacking/Blending de plusieurs modÃ¨les
- [ ] **Deep Learning** : ExpÃ©rimentation avec des rÃ©seaux de neurones
- [ ] **AutoML** : Optimisation automatique avec AutoSklearn ou TPOT
- [ ] **Containerisation** : Docker pour dÃ©ploiement simplifiÃ©
- [ ] **CI/CD** : Pipeline automatisÃ© de tests et dÃ©ploiement
- [ ] **Base de donnÃ©es** : Migration vers PostgreSQL pour donnÃ©es volumineuses
- [ ] **Caching** : Redis pour amÃ©liorer les performances

### Contributions bienvenues

Nous accueillons les contributions dans les domaines suivants :
- ğŸ› Correction de bugs
- âœ¨ Nouvelles fonctionnalitÃ©s
- ğŸ“ AmÃ©lioration de la documentation
- ğŸ§ª Ajout de tests
- ğŸ¨ AmÃ©lioration de l'interface utilisateur
- ğŸŒ Traductions

## ğŸ“š Ressources

### Documentation technique

- [Documentation scikit-learn](https://scikit-learn.org/) - BibliothÃ¨que ML principale
- [Documentation XGBoost](https://xgboost.readthedocs.io/) - Algorithme de boosting
- [Documentation Streamlit](https://docs.streamlit.io/) - Framework d'interface web
- [Documentation pandas](https://pandas.pydata.org/docs/) - Manipulation de donnÃ©es
- [Documentation pytest](https://docs.pytest.org/) - Framework de tests

### Ressources acadÃ©miques

- [Article original du dataset](https://www.sciencedirect.com/science/article/pii/S2352340918315191) - Antonio, Almeida and Nunes (2019)
- [Kaggle Dataset](https://www.kaggle.com/datasets/jessemostipak/hotel-booking-demand) - Source des donnÃ©es
- [SMOTE Paper](https://arxiv.org/abs/1106.1813) - Technique de gestion du dÃ©sÃ©quilibre
- [Random Forest Paper](https://link.springer.com/article/10.1023/A:1010933404324) - Breiman (2001)

### Tutoriels et guides

- [Guide de dÃ©ploiement Streamlit Cloud](https://docs.streamlit.io/streamlit-community-cloud/get-started)
- [Best practices ML en production](https://ml-ops.org/)
- [Guide de feature engineering](https://www.kaggle.com/learn/feature-engineering)
- [InterprÃ©tabilitÃ© des modÃ¨les ML](https://christophm.github.io/interpretable-ml-book/)
